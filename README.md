# Removing_duplicate_file_in_a_Directory
Program that helps to delete the redundant entries with same file name and hashfile blocksize  over the provided path

Steps to Perform and Experience:
1) Keep the file named - removing_duplicate_file.py in the directory over which you likely need to do redundant file check.
2) Get the file name which you likely need to remove the duplicate entries over the assocated directory PATH.
3) hard-code the directory path to variable named:directory_path  over which you likely to remove duplicate entries of file
4) run the program with  : "python3 removing_duplicate_file.py" and verify redundant files are deleted successfully over the hard-coded directory path.
